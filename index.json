[{"authors":null,"categories":null,"content":"I\u0026rsquo;m currently a PhD candidate at the Department of Library and Information Science, University of Delhi, India. My PhD thesis, \u0026ldquo;Analyzing Trends in Electronic Theses and Dissertations: 100 years of Library and Information Science\u0026rdquo;, is the first doctoral thesis in India that focuses on the application of computational methods such as topic modeling, network analysis, and machine learning in the field of library and information science (LIS). As the number of textual data, including ETDs, increases exponentially every day over the web, the issue of organizing, managing, and disseminating information poses a challenge. My PhD research aims to forward a solution to the above problem by applying topic modeling, network analysis, and machine learning to the ETDs submitted to the ProQuest Dissertations and Theses (PQDT) Global database from 1903 to 2020. I’m particularly interested to identify the highly-and-under researched areas in LIS over 100 years and understand the evolution of LIS discipline in different countries. I’m currently working on developing a website that will allow readers to explore the topic modeling results from my published papers/projects.\n​In addition to my thesis research, I am also fascinated to use computational methods to analyze digital trace data. In 2018, I published a paper where I analyzed twitter data for 20 different facets of economic productivity. Recently in June 2020, I was selected to attend a two-week research-based summer-program in computational social science (SCISS 2020) that covered automated text analysis, website scraping, digital field experiments, non-probability sampling, mass collaboration, ethics, machine learning, network analysis, and many other issues. Currently, I am working on four different research projects besides my doctoral research. In addition to these projects, I have worked as a teaching assistant in my department.\n","date":1610323200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1610323200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://manika-lamba.github.io/author/manika-lamba/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/manika-lamba/","section":"authors","summary":"I\u0026rsquo;m currently a PhD candidate at the Department of Library and Information Science, University of Delhi, India. My PhD thesis, \u0026ldquo;Analyzing Trends in Electronic Theses and Dissertations: 100 years of Library and Information Science\u0026rdquo;, is the first doctoral thesis in India that focuses on the application of computational methods such as topic modeling, network analysis, and machine learning in the field of library and information science (LIS).","tags":null,"title":"Manika Lamba","type":"authors"},{"authors":null,"categories":null,"content":"1. Text Mining\nA short introductory video on text mining for libraries.   2. Topic Modeling\na. This video gives a theoretical framework for topic modeling based on latent Dirichlet allocation (LDA) with a special reference to ETDs and libraries.   b. This video provides hands-on training on performing and visualizing topic modeling based on Latent Dirichlet Allocation using R. Shodhganga is an open-access repository, so you can download ETDs from it for free and analyse it! You can download the theses in any subject you want from its website - https://shodhganga.inflibnet.ac.in   c. Topic-Modeling-Tool is a graphical user interface tool for topic modeling based on Latent Dirichlet Allocation (LDA). It uses MALLET at the back-end to analyze large volumes of unlabeled text. A \u0026ldquo;topic\u0026rdquo; consists of a cluster of words that frequently occur together. Using contextual clues, topic models can connect words with similar meanings and distinguish between uses of words with multiple meanings.\n  3. Predictive Modeling/Machine Learning\nA short introductory video on prediction modeling (also known as supervised machine learning or predictive modeling).\n  ","date":-62135596800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":-62135596800,"objectID":"81a8db348afe81bd4ad6991b8727cff6","permalink":"https://manika-lamba.github.io/videos/youtube.1/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/videos/youtube.1/","section":"videos","summary":"Covering text mining, topic modeling, and predictive modeling/machine learning topics.","tags":null,"title":"Computational Methods","type":"docs"},{"authors":null,"categories":null,"content":"1. Convert .pdf to .txt\nThis video shows the conversion of documents from .pdf to .txt format in R. Link to download XpdfReader: https://www.xpdfreader.com/download.html\n  ","date":1612828800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1612828800,"objectID":"2dd62791f45d54ea711aa4f2b5ca1a74","permalink":"https://manika-lamba.github.io/videos/youtube.2/","publishdate":"2021-02-09T00:00:00Z","relpermalink":"/videos/youtube.2/","section":"videos","summary":"1. Convert .pdf to .txt\nThis video shows the conversion of documents from .pdf to .txt format in R. Link to download XpdfReader: https://www.xpdfreader.com/download.html\n  ","tags":null,"title":"Learn R","type":"docs"},{"authors":null,"categories":null,"content":"1. Build Academic CV/Resume in Overleaf\nLearn how to make an academic CV/Resume using LaTex open-source software \u0026mdash; Overleaf.\nGuide to Overleaf: https://www.overleaf.com/learn/latex/Bold,_italics_and_underlining\nLink of the template used in the video: https://www.overleaf.com/latex/templates/prometheuscv/hhkdyvbtvhsq\n  ","date":1612828800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1612828800,"objectID":"9f9c5fc4d46876ab348381524874672f","permalink":"https://manika-lamba.github.io/videos/youtube.3/","publishdate":"2021-02-09T00:00:00Z","relpermalink":"/videos/youtube.3/","section":"videos","summary":"1. Build Academic CV/Resume in Overleaf\nLearn how to make an academic CV/Resume using LaTex open-source software \u0026mdash; Overleaf.\nGuide to Overleaf: https://www.overleaf.com/learn/latex/Bold,_italics_and_underlining\nLink of the template used in the video: https://www.","tags":null,"title":"Learn LaTex","type":"docs"},{"authors":null,"categories":null,"content":"Question 1 : How to overcome major biases in social media research data?\n  Question 2 : Is there any ethical framework for social media research?\n  ","date":1612828800,"expirydate":-62135596800,"kind":"section","lang":"en","lastmod":1612828800,"objectID":"8708b8d65cce686f0f4ca2bf73c2b8ab","permalink":"https://manika-lamba.github.io/videos/youtube.4/","publishdate":"2021-02-09T00:00:00Z","relpermalink":"/videos/youtube.4/","section":"videos","summary":"I was invited as a discussant to the \"Social Media Research\" session in LTC2021​​. This section consists of two short videos where you will get answers to the two questions I asked during the session.","tags":null,"title":"Social Media Research session in LTC2021","type":"docs"},{"authors":["Manika Lamba","Neha Kashyap","Margam Madhusudhan"],"categories":null,"content":"","date":1610323200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610323200,"objectID":"85d9c7c6ef78c7cc343770bf79143fa9","permalink":"https://manika-lamba.github.io/publication/journal-article/9/","publishdate":"2021-01-11T00:00:00Z","relpermalink":"/publication/journal-article/9/","section":"publication","summary":"Social interaction applications and reference tools (generally web-based) are actively used by researchers to share and manage their research publications. Thus, this paper aims to determine the scholarly impact of selected Indian central universities. This study analyzed 669 articles having both dimensions citations and altmetric attention scores published by 35 Indian central universities for four subfields of computer science using Altmetric Explorer. This paper determined each university’s contribution in the studied subfields of computer science and the correlation among altmetric attention score (aggregated and individual), dimensions citation, and Mendeley readership counts for all 669 articles and stratified percentile sets of top 25%, and top 50% of the overall number of articles. The findings showed that Jawaharlal Nehru University (JNU) had the maximum altmetric attention score, Banaras Hindu University (BHU) received the maximum dimensions citation, and University of Hyderabad (UoH) received the maximum number of Mendeley readers. Each central university was examined individually and then ranked based on their median values of dimensions citations and altmetric attention scores. Further, Twitter had the maximum altmetric coverage, followed by google+, patent, and facebook for the retrieved articles. A significant strong positive correlation was observed between the dimensions citation and Mendeley readership counts for all the three categories. Both altmetric attention scores and dimensions citations can help funding agencies to assess and evaluate the research productivity of these universities and thus, making important decisions such as increasing or decreasing or re-distributing their funds. The current body of research is focused mostly on relationships between citations and individual altmetric indicators predominantly. For most of the studies, the citations were retrieved from Scopus, Web of Science, or Google Scholar database. It was observed that by far, no study had examined the relationship between citations retrieved from Dimensions database, altmetrics scores (both aggregated and individual), and Mendeley readership counts.","tags":null,"title":"Research Evaluation of Computer Science Departments: A Cohort Study of Indian Central Universities","type":"publication"},{"authors":null,"categories":null,"content":"","date":1609027200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609027200,"objectID":"8f66d660a9a2edc2d08e68cc30f701f7","permalink":"https://manika-lamba.github.io/project/internal-project/","publishdate":"2020-12-27T00:00:00Z","relpermalink":"/project/internal-project/","section":"project","summary":"","tags":["Dashboard"],"title":"Dashboard","type":"project"},{"authors":["K.C. Garg","Manika Lamba","Rahul Kumar Singh"],"categories":null,"content":"","date":1607644800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607644800,"objectID":"add4c379bdfe2f0ccee696fcf1a710d3","permalink":"https://manika-lamba.github.io/publication/journal-article/8/","publishdate":"2020-12-11T00:00:00Z","relpermalink":"/publication/journal-article/8/","section":"publication","summary":"The study analyses papers published in DESIDOC Journal of Library and Information Technology (DJLIT) using bibliometric techniques for the period of 1992-2019 (28 years) and citations received by these papers until 20th March 2020as reflected by Google Scholar. The study examined the pattern of growth, geographical distribution of the articles; identified the prolific authors \u0026 institutions, and their output; and the pattern of citations of the papers and identified most cited authors. The findings indicate that the highest number of articles was published during 2012-2015 followed by 2016-2019. The distribution of output by countries indicates that 39 countries contributed 1,698 articles, including India. Indian authors published the highest percentage (86.1 %) of articles followed by USA and had the highest value of CPP and RCI. Authors affiliated to different institutions of Delhi contributed the most (30.7 %) followed by Karnataka (13.1 %) and Maharashtra (10.5 %). Among the institutions, DRDO-DESIDOC and CSIR-NISTADS topped the list. Among the 26 most prolific authors, B.M. Gupta (CSIR-NISTADS) published the maximum number of articles. However, B.R. Babu (University of Madras, Chennai) had the highest value of CPP and RCI. During the studied period, 1,698 papers obtained 15,538 citations, of which 248 (14.6 %) articles did not receive any citation.","tags":null,"title":"Bibliometric Analysis of papers published during 1992 to 2019 in DESIDOC Journal of Library and Information Technology","type":"publication"},{"authors":["Manika Lamba"],"categories":null,"content":"","date":1585699200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585699200,"objectID":"0b224ef00f9d2b40c992a36ab1d80feb","permalink":"https://manika-lamba.github.io/publication/journal-article/2/","publishdate":"2020-04-01T00:00:00Z","relpermalink":"/publication/journal-article/2/","section":"publication","summary":"In today’s publish or perish environment, the scholarly impact of a research article holds great importance. The present study examined 2343 articles having both altmetric attention scores and citations published by 22 core health care policy faculty members at Harvard Medical School. Web of Science was used to retrieve the citations, whereas Altmetric Explorer was used to determine the altmetric attention score. The evaluation metrics in this study were focused on article-level information to determine each faculty member’s contribution to the health care policy department collected in November 2018. This paper further determined the predictive capability of altmetric attention score for the increase of citations from November 2018 to January 2020. The findings showed J. Michael McWilliams (Professor); Anupam B. Jena (Associate Professor); and Zirui Song (Assistant Professor) were the faculty members with highest altmetric attention score while Ronald C. Kessler (Professor); Nicole Maestas (Associate Professor); and Zirui Song (Assistant Professor) were the faculty members with the highest citation value. The lowest percentage (5.84%) of articles without any citations were published by the professors, whereas the lowest percentage (4.84%) of articles without any social media mention were published by the assistant professors. The health care faculty had the highest percentage of Mendeley readerships followed by tweets, news, and blogs mention in comparison to a meager percentage of policy-related documents mention for their retrieved articles. A significant strong positive correlation (rR  0.4) was observed between the aggregated ranked altmetric attention scores and ranked citation/increased citation values for all the faculty members. This study can be extended to determine the research productivity of any department, discipline, or group of faculty members.","tags":null,"title":"Research productivity of health care policy faculty: a cohort study of Harvard Medical School","type":"publication"},{"authors":null,"categories":null,"content":"","date":1585645200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1585645200,"objectID":"969ac2cd3ec793523773cd93cf2d83c9","permalink":"https://manika-lamba.github.io/talk/2021-ltc/","publishdate":"2020-03-31T09:00:00Z","relpermalink":"/talk/2021-ltc/","section":"talk","summary":"I was invited as a discussant for the Social Media Research session in LTC2021​. In this short clip, you will get answers to How to overcome major biases in social media research data by the panelists of the session.","tags":null,"title":"Social Media Research","type":"talk"},{"authors":["Manika Lamba","Margam Madhusudhan"],"categories":null,"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"81c7022f7b553b32ea108c0d860e398f","permalink":"https://manika-lamba.github.io/publication/journal-article/3/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/publication/journal-article/3/","section":"publication","summary":"The information explosion in the form of ETDs poses the challenge of management and extraction of appropriate knowledge for decision making by information practitioners. This study presents a solution to the problem by applying topic mining and prediction modeling to 441 full-text ETDs extracted from the PQDT Global database during 2014-2018 in the field of library science using the RapidMiner platform. This study was divided into three phases. In the first phase, metadata analysis of the ETDs retrieved from the database was performed to identify the association of various entities such as universities, departments, types of degrees, and geographical areas with the ETDs. In the second phase, 8 core topics namelychildren literature; academic library; information retrieval; archival science; user study; digital library; library leadership; and digital communication were determined using latent dirichlet allocation (LDA) and each ETD was then annotated with the modeled topic. Lastly, a prediction model using the Support Vector Machine (SVM) was created to classify the untagged ETDs going to be submitted in the database under the 8 modeled topics ( a to h ).","tags":null,"title":"Mapping of ETDs in ProQuest dissertations and theses (PQDT) global database  (2014-2018)","type":"publication"},{"authors":["Manika Lamba"],"categories":null,"content":"","date":1572566400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1572566400,"objectID":"90ef2d45b6a9cf9dc715a691c3557e32","permalink":"https://manika-lamba.github.io/publication/conference-paper/1/","publishdate":"2019-11-01T00:00:00Z","relpermalink":"/publication/conference-paper/1/","section":"publication","summary":"The information explosion in the form of ETDs poses the challenge of management and extraction of appropriate knowledge for decision making. Thus, the present study forwards a solution to the above problem by applying topic mining and prediction modeling tools to full-text 263 ETDs submitted to the PQDT Global database during 2016-18 in the field of library science. This study was divided into two phases. The first phase determined the core topics from the ETDs using Topic-Modeling-Tool (TMT), which was based on latent dirichlet allocation (LDA), whereas the second phase employed prediction analysis using RapidMiner platform to annotate the future research articles on the basis of the modeled topics. The core topics (tags) for the studied period were found to be book history, school librarian, public library, communicative ecology, and informatics followed by text network and trend analysis on the high probability co-occurred words. Lastly, a prediction model using the Support Vector Machine (SVM) classifier was created in order to accurately predict the placement of future ETDs going to be submitted to PQDT Global under the five modeled topics (a to e). The tested dataset against the trained data set for the predictive performed perfectly.","tags":null,"title":"Text Analysis of ETDs in ProQuest Dissertations and Theses (PQDT) Global (2016-2018)","type":"publication"},{"authors":null,"categories":null,"content":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.\nOn this page, you\u0026rsquo;ll find some examples of the types of technical content that can be rendered with Academic.\nExamples Code Academic supports a Markdown extension for highlighting code syntax. You can enable this feature by toggling the highlight option in your config/_default/params.toml file.\n```python import pandas as pd data = pd.read_csv(\u0026quot;data.csv\u0026quot;) data.head() ```  renders as\nimport pandas as pd data = pd.read_csv(\u0026#34;data.csv\u0026#34;) data.head() Charts Academic supports the popular Plotly chart format.\nSave your Plotly JSON in your page folder, for example chart.json, and then add the {{\u0026lt; chart data=\u0026quot;chart\u0026quot; \u0026gt;}} shortcode where you would like the chart to appear.\nDemo:\n  (function() { let a = setInterval( function() { if ( typeof window.Plotly === 'undefined' ) { return; } clearInterval( a ); Plotly.d3.json(\"./line-chart.json\", function(chart) { Plotly.plot('chart-816532947', chart.data, chart.layout, {responsive: true}); }); }, 500 ); })();  You might also find the Plotly JSON Editor useful.\nMath Academic supports a Markdown extension for $\\LaTeX$ math. You can enable this feature by toggling the math option in your config/_default/params.toml file.\nTo render inline or block math, wrap your LaTeX math with $...$ or $$...$$, respectively.\nExample math block:\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |} {\\left \\|\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right \\|^2}$$ renders as\n$$\\gamma_{n} = \\frac{ \\left | \\left (\\mathbf x_{n} - \\mathbf x_{n-1} \\right )^T \\left [\\nabla F (\\mathbf x_{n}) - \\nabla F (\\mathbf x_{n-1}) \\right ] \\right |}{\\left |\\nabla F(\\mathbf{x}_{n}) - \\nabla F(\\mathbf{x}_{n-1}) \\right |^2}$$\nExample inline math $\\nabla F(\\mathbf{x}_{n})$ renders as $\\nabla F(\\mathbf{x}_{n})$.\nExample multi-line math using the \\\\\\\\ math linebreak:\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\\\\\ 1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$ renders as\n$$f(k;p_0^*) = \\begin{cases} p_0^* \u0026amp; \\text{if }k=1, \\\\\n1-p_0^* \u0026amp; \\text {if }k=0.\\end{cases}$$\nDiagrams Academic supports a Markdown extension for diagrams. You can enable this feature by toggling the diagram option in your config/_default/params.toml file or by adding diagram: true to your page front matter.\nAn example flowchart:\n```mermaid graph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] ```  renders as\ngraph TD A[Hard] --\u0026gt;|Text| B(Round) B --\u0026gt; C{Decision} C --\u0026gt;|One| D[Result 1] C --\u0026gt;|Two| E[Result 2] An example sequence diagram:\n```mermaid sequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! ```  renders as\nsequenceDiagram Alice-\u0026gt;\u0026gt;John: Hello John, how are you? loop Healthcheck John-\u0026gt;\u0026gt;John: Fight against hypochondria end Note right of John: Rational thoughts! John--\u0026gt;\u0026gt;Alice: Great! John-\u0026gt;\u0026gt;Bob: How about you? Bob--\u0026gt;\u0026gt;John: Jolly good! An example Gantt diagram:\n```mermaid gantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d ```  renders as\ngantt section Section Completed :done, des1, 2014-01-06,2014-01-08 Active :active, des2, 2014-01-07, 3d Parallel 1 : des3, after des1, 1d Parallel 2 : des4, after des1, 1d Parallel 3 : des5, after des3, 1d Parallel 4 : des6, after des4, 1d An example class diagram:\n```mermaid classDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() } ```  renders as\nclassDiagram Class01 \u0026lt;|-- AveryLongClass : Cool \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; Class01 Class09 --\u0026gt; C2 : Where am i? Class09 --* C3 Class09 --|\u0026gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla class Class10 { \u0026lt;\u0026lt;service\u0026gt;\u0026gt; int id size() } An example state diagram:\n```mermaid stateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*] ```  renders as\nstateDiagram [*] --\u0026gt; Still Still --\u0026gt; [*] Still --\u0026gt; Moving Moving --\u0026gt; Still Moving --\u0026gt; Crash Crash --\u0026gt; [*] Todo lists You can even write your todo lists in Academic too:\n- [x] Write math example - [x] Write diagram example - [ ] Do something else renders as\n Write math example Write diagram example Do something else  Tables Represent your data in tables:\n| First Header | Second Header | | ------------- | ------------- | | Content Cell | Content Cell | | Content Cell | Content Cell | renders as\n   First Header Second Header     Content Cell Content Cell   Content Cell Content Cell    Callouts Academic supports a shortcode for callouts, also referred to as asides, hints, or alerts. By wrapping a paragraph in {{% alert note %}} ... {{% /alert %}}, it will render as an aside.\n{{% alert note %}} A Markdown aside is useful for displaying notices, hints, or definitions to your readers. {{% /alert %}} renders as\n A Markdown aside is useful for displaying notices, hints, or definitions to your readers.   Spoilers Add a spoiler to a page to reveal text, such as an answer to a question, after a button is clicked.\n{{\u0026lt; spoiler text=\u0026#34;Click to view the spoiler\u0026#34; \u0026gt;}} You found me! {{\u0026lt; /spoiler \u0026gt;}} renders as\n Click to view the spoiler  You found me!    Icons Academic enables you to use a wide range of icons from Font Awesome and Academicons in addition to emojis.\nHere are some examples using the icon shortcode to render icons:\n{{\u0026lt; icon name=\u0026#34;terminal\u0026#34; pack=\u0026#34;fas\u0026#34; \u0026gt;}} Terminal {{\u0026lt; icon name=\u0026#34;python\u0026#34; pack=\u0026#34;fab\u0026#34; \u0026gt;}} Python {{\u0026lt; icon name=\u0026#34;r-project\u0026#34; pack=\u0026#34;fab\u0026#34; \u0026gt;}} R renders as\n  Terminal\n Python\n R\nDid you find this page helpful? Consider sharing it 🙌 ","date":1562889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562889600,"objectID":"4cfcdd4b86a0792bf461e9d7340360a7","permalink":"https://manika-lamba.github.io/post/icdl2019/","publishdate":"2019-07-12T00:00:00Z","relpermalink":"/post/icdl2019/","section":"post","summary":"Academic is designed to give technical content creators a seamless experience. You can focus on the content and Academic handles the rest.\nHighlight your code snippets, take notes on math classes, and draw diagrams from textual representation.","tags":null,"title":"Writing technical content in Academic","type":"post"},{"authors":["Manika Lamba","Margam Madhusudhan"],"categories":null,"content":"","date":1559865600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559865600,"objectID":"54d099dd6296ba6e48271ac2f38650bd","permalink":"https://manika-lamba.github.io/publication/journal-article/1/","publishdate":"2019-06-07T00:00:00Z","relpermalink":"/publication/journal-article/1/","section":"publication","summary":"This study analyzed 928 full-text research articles retrieved from DESIDOC Journal of Library and Information Technology for the period of 1981–2018 using Latent Dirichlet Allocation. The study further tagged the articles with the modeled topics. 50 core topics were identified throughout the period of 38 years whereas only 26 topics were unique in nature. Bibliometrics, ICT, information retrieval, and user studies were highly researched areas in India for the epoch. Further, Spain and Taiwan showed common research trends and areas as India whereas India has quite distinct research interests from America and China. Therefore, researchers in Library and Information Science in India should pay more attention to the topics which are under-researched. Further, it was found that there were some unique sub-fields to Indian Library and Information Science research, such as open access; online exhibition; virtual libraries; multimedia libraries; open source software; library automation; and library management system. With the passage of time topics evolve over time, new topics emerge, and old ones become obsolete. Topic modeling not only helps the researcher to determine the trending themes or related fields with respect to their field of interest but also helps them to identify new concepts and fields over time.","tags":null,"title":"Mapping of topics in DESIDOC Journal of Library and Information  Technology,  India: a study","type":"publication"},{"authors":["Manika Lamba","Margam Madhusdhan"],"categories":null,"content":"","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559347200,"objectID":"82da7ff731609bcda3604bd0e3aa9912","permalink":"https://manika-lamba.github.io/publication/journal-article/4/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/publication/journal-article/4/","section":"publication","summary":"The present paper describes the importance and usage of metadata tagging and prediction modeling tools for researchers and librarians. 387 articles were downloaded from DESIDOC Journal of Library and Information Technology (DJLIT) for the period 2008-17 excluding guest editorials and special editions. This study was divided into two phases. The first phase determined the core Topics from the research articles using Topic-Modeling-Tool (TMT) , which was based on latent Dirichlet allocation (LDA), whereas the second phase employed prediction analysis using RapidMiner toolbox to annotate the future research articles on the basis of the modeled topics. The core topics (tags) were found to be digital libraries, information literacy, scientometrics, open access, and library resources for the studied period. This study further annotated the scientific articles according to the modeled topics to provide a better searching experience to its users. Sugimoto, Li, Russell, et al. (2011), Figuerola, Marco, and Pinto (2017), and Lamba and Madhusudhan (2018) have performed studies similar to the present paper but with major modifications.","tags":null,"title":"Metadata Tagging and Prediction Modeling: Case Study of DESIDOC  Journal of  Library and Information Technology (2008–17)","type":"publication"},{"authors":["Manika Lamba","Margam Madhusdhan"],"categories":null,"content":"","date":1556668800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556668800,"objectID":"a3a8081c13e491b60accd88639f95237","permalink":"https://manika-lamba.github.io/publication/journal-article/6/","publishdate":"2019-05-01T00:00:00Z","relpermalink":"/publication/journal-article/6/","section":"publication","summary":"This study presents a method to analyze textual data and applying it to the field of Library and Information Science. This paper subsumes a special case of Latent Dirichlet Allocation and Author-Topic models where each article has one unique author and each author has one unique topic. Topic Modeling Toolkit is used to perform the author-topic modeling. The study further which considers topics and their changes over time by taking into account both the word co-occurrence pattern and time. 393 full-text articles were downloaded from DESIDOC Journal of Library and Information Technology and were analyzed accordingly. 16 core topics have been identified throughout the period of ten years. These core topics can be considered as the core area of research in the journal from 2008 to 2017. This paper further identifies top five authors associated with the representative articles for each studied year. These authors can be treated as the subject-experts for the modeled topics as indicated. The results of the study can serve as a platform to determine the research trend; core areas of research; and the subject-experts related to those core areas in the field the Library and Information Science in India.","tags":null,"title":"Author-Topic Modeling of DESIDOC Journal of Library and Information Technology (2008-2017), India","type":"publication"},{"authors":["Manika Lamba"],"categories":null,"content":"","date":1552262400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552262400,"objectID":"cc84020a19b050f33cd95765b3da6587","permalink":"https://manika-lamba.github.io/publication/journal-article/5/","publishdate":"2019-03-11T00:00:00Z","relpermalink":"/publication/journal-article/5/","section":"publication","summary":"The advent of Web 2.0 in libraries persuades the librarians to adopt new ways to communicate, determine, and satisfy the needs of the users. The paper aims to discuss this issue. A 30-question questionnaire was given to 30 undergraduate medical students of Vardhman Mahavir Medical College and a 10-question questionnaire was given to the librarian, to find out the marketing and promotional strategies employed by the library; determine the awareness and satisfaction level of the users; prepare library profile, customer profile and market profile; and perform SWOT analysis. User responses were coded and processed using GNU PSPP software. From the library profile of Vardhman Mahavir Medical College library, it can be concluded that the library has the potential to offer better services and products to its users. From the customer profile of Vardhman Mahavir Medical College library, it is concluded that the most of its users are young male undergraduate students who use the library more on weekly basis. From the market profile of Vardhman Mahavir Medical College library, it is concluded that the library has not invested in the marketing and has no promotion strategy or marketing strategy for its products and services. Also, the library has only one digital promotional activity. From the SWOT analysis of Vardhman Mahavir Medical College library, it is concluded that the library does not use any of the social platforms to market its products and services. Most of the users are unaware of the services and products offered by the library. There are many opportunities for the library to work upon and improve the quality of products and services being offered to its users. The major limitation of the present study is its small sample size. It is very difficult to conduct surveys in health libraries because of the busy schedule of the undergraduate medical students and their reluctance to fill out lengthy questionnaires. However, this small sample size only made it possible to conduct the SWOT analysis on the basis of the users’ survey successfully. Further, the small sample size helped to take into account all the opportunities stated by the users which would not have been possible if a larger sample size was taken. This study is one of a kind which provides an overview of marketing research of an academic health library of New Delhi (India) with a special focus on library profile, market profile, customer profile and SWOT analysis. It addresses the gaps in the literature by studying marketing in the context of academic health libraries in the digital environment.","tags":null,"title":"Marketing of academic health libraries 2.0: a case study","type":"publication"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic  Academic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click  PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026#34;blueberry\u0026#34; if porridge == \u0026#34;blueberry\u0026#34;: print(\u0026#34;Eating...\u0026#34;)  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}} Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}} Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026#34;/media/boards.jpg\u0026#34; \u0026gt;}} {{\u0026lt; slide background-color=\u0026#34;#0000FF\u0026#34; \u0026gt;}} {{\u0026lt; slide class=\u0026#34;my-style\u0026#34; \u0026gt;}}  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }  Questions?  Ask\n Documentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"https://manika-lamba.github.io/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Manika Lamba"],"categories":null,"content":"","date":1548979200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548979200,"objectID":"6d333251708ed0b40ec11df3a7520b0e","permalink":"https://manika-lamba.github.io/publication/book-chapter/2/","publishdate":"2019-02-01T00:00:00Z","relpermalink":"/publication/book-chapter/2/","section":"publication","summary":"The advent of Web 2.0 in libraries persuades the librarians to adopt new ways to communicate, determine and satisfy the needs of the users. For this study a questionnaire was given to the medical students of University College of Medical Sciences and another questionnaire was given to the librarian, to find out, the marketing and promotional strategies employed by the library; determine the awareness and satisfaction level of the users; prepare customer profile and market profile, and perform SWOT analysis. The data were coded and processed using GNU PSPP software. The findings of the study show that the library does not use any of the social platforms to market its products and services and most of the users are unaware of the services and products offered by the library. There are many opportunities for the library to work upon and improve the quality of products and services being offered to its users. Digital marketing is the latest marketing trend using web 2.0 tools but is rarely employed by academic health libraries in India.","tags":null,"title":"Marketing of University College of Medical Sciences Library, University of Delhi A Study","type":"publication"},{"authors":["Manika Lamba","Margam Madhusdhan"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"9d1f2d5a54a5735a771ec67e31072ad1","permalink":"https://manika-lamba.github.io/publication/book-chapter/1/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/publication/book-chapter/1/","section":"publication","summary":"This chapter presents a conceptual framework of Sentiment Analysis and its application in the field of Library and Information Science. Sentiment Analysis of social media platforms will help the policy makers, researchers, and market analysts to understand the views and opinions generated by the public on an international platform related to the various facets of libraries.","tags":null,"title":"New Paradigm in Library 2.0 Sentiment Analysis of Twitter","type":"publication"},{"authors":["Manika Lamba"],"categories":null,"content":"","date":1537056000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1537056000,"objectID":"df2e2cd2e97252cdadc015d25172109d","permalink":"https://manika-lamba.github.io/post/etd2018/","publishdate":"2018-09-16T00:00:00Z","relpermalink":"/post/etd2018/","section":"post","summary":"","tags":null,"title":"ETD 2019 (Taipei, Taiwan)","type":"post"},{"authors":["Manika Lamba","Margam Madhusdhan"],"categories":null,"content":"","date":1535760000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1535760000,"objectID":"a9b799c71cc7db87395d657cd5c66fac","permalink":"https://manika-lamba.github.io/publication/conference-paper/2/","publishdate":"2018-09-01T00:00:00Z","relpermalink":"/publication/conference-paper/2/","section":"publication","summary":"Electronic Theses and Dissertations (ETDs) poses the challenge of managing and extraction of appropriate knowledge for decision making. To tackle the same, topic modeling was first applied to Library and Information Science (LIS) theses submitted to Shodhganga (an Indian ETDs digital repository) to determine the five core topics/tags and then the performance of the built model based on those topics/tags were analyzed. Using a Latent Dirichlet Allocation based Topic-Modeling-Toolkit, the five core topics were found to be information literacy, user studies, scientometrics, library resources and library services for the epoch 2013-2017 and consequently all the theses were summarized with the presence of their respective topic proportion for the tags/topics. A Support Vector Machine (Linear) prediction model using RapidMiner toolbox was created and showed 88.78% accuracy with 0.85 kappa value.","tags":null,"title":"Metadata Tagging of Library and Information Science Theses Shodhganga (2013-2017)","type":"publication"},{"authors":["Manika Lamba","Margam Madhusdhan"],"categories":null,"content":"","date":1534636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534636800,"objectID":"a4f492d57d2046b72af3c560a0eb5b88","permalink":"https://manika-lamba.github.io/publication/journal-article/7/","publishdate":"2018-08-19T00:00:00Z","relpermalink":"/publication/journal-article/7/","section":"publication","summary":"With the advent of social media, people have found new ways through which they can express their views, opinions, and beliefs . This study presents an interdisciplinary nature of research where sentiment analysis is applied to the economics discipline of productivity as an experimental study to introduce new service for libraries’ users. Firstly, data were retrieved from Twitter on 20 different queries related to productivity using RapidMiner platform and then sentiment analysis was performed employing AYLIEN Text Analysis Software. A total of 6416 tweets were mined from Twitter for a period of 13 days. Further, 676 prominent hashtags had been identified where 83 hashtags were found to be associated with a geographical location in the tweets. It was observed that the United Kingdom was the most popular country which was being used as a hashtag on Twitter in relation to various facets of the productivity followed by India, the United States, China, and Nigeria. In regard to polarity, most of the tweets were found to be of neutral polarity and most of the positive tweets had a low percentage value. The information analyzed using this strategy can be repackaged as a consolidated time-based service and can be presented to libraries’ users in different formats. This study not only introduces a nascent way to cater to the information needs of today’s users, but also proposes a new way of conducting marketing in libraries using social media mining and sentiment analysis.","tags":null,"title":"Application of sentiment analysis in libraries to provide temporal information service: a case study on various facets of productivity","type":"publication"},{"authors":["Manika Lamba","Margam Madhusudhan"],"categories":null,"content":"","date":1517356800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1517356800,"objectID":"c12dc097a13ffa2b426232b59459e6d3","permalink":"https://manika-lamba.github.io/publication/book-chapter/3/","publishdate":"2018-01-31T00:00:00Z","relpermalink":"/publication/book-chapter/3/","section":"publication","summary":"This chapter presents a method for analyzing text data called topic modeling and applying it to the field of Library and Information Science. It describes the importance and usage of topic mining for researchers and librarians. An experiment study is also covered which applies topic modeling in a real scenario, where five model topics for the articles published in DESIDOC Journal of Library and Information Technology for the year 2017 using Topic-Modeling-Toolkit and prediction modeling is constructed using RapidMiner toolbox.","tags":null,"title":"Application of Topic Mining and Prediction Modeling Tools for Library and Information Science Journals","type":"publication"},{"authors":["Manika Lamba"],"categories":null,"content":"","date":1508976000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1508976000,"objectID":"79b4b22b73b635638d70c8d00ffffacb","permalink":"https://manika-lamba.github.io/publication/conference-paper/3/","publishdate":"2017-08-26T00:00:00Z","relpermalink":"/publication/conference-paper/3/","section":"publication","summary":"This article deals with the need of marketing of library products and services in medical libraries in the digital environment. It analyses the data collected from the two major medical libraries of India using GNU PSPP software and draw comparison among their marketing strategies.","tags":null,"title":"Marketing of LIS Products and Services in Select Medical Libraries of Delhi in Digital Environment: A Comparative Study","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"7ecdd4a6de39fb3c3d4ff43482669f6a","permalink":"https://manika-lamba.github.io/project/projects/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/projects/","section":"project","summary":"","tags":null,"title":"Projects","type":"project"}]